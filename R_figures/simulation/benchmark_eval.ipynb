{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python3 -m pip install pyliger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/BCCRC.CA/yzhang/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import pyliger\n",
    "from DeltaTopic.nn.util_benchmark import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'BALSAM_ep2000_nlv32_simseed11_seed11_N10000_G5000_T16_topk100_pip0.1_v4'\n",
    "adata = sc.read(os.path.join('models', model_id, 'adata.h5ad'))\n",
    "N, G = adata.shape\n",
    "\n",
    "theta = np.genfromtxt(os.path.join('models', model_id, 'topics.csv'), delimiter=',', skip_header=1)\n",
    "theta = theta[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_unspliced = adata.copy()\n",
    "adata_unspliced.X = adata.obsm[\"unspliced_expression\"].copy()\n",
    "adata_concat = ad.concat([adata, adata_unspliced])\n",
    "\n",
    "T = 32\n",
    "topic_label = create_topic_label(N, T)\n",
    "topic_label_1d = np.sum(topic_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8378986635872715"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmi = compute_nmi(topic_label, theta)\n",
    "nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the PCA\n",
    "adata.X = adata.layers['counts'].copy()\n",
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "# Compute the neighborhood graph\n",
    "sc.pp.neighbors(adata, n_pcs=T, use_rep='X_pca')\n",
    "# Compute the Louvain clusters\n",
    "sc.tl.louvain(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8048853714635366"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmi_pca = normalized_mutual_info_score(topic_label_1d, adata.obs['louvain'])\n",
    "nmi_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the PCA\n",
    "adata_concat.X = adata_concat.layers['counts'].copy()\n",
    "sc.tl.pca(adata_concat, svd_solver='arpack')\n",
    "# Compute the neighborhood graph\n",
    "sc.pp.neighbors(adata_concat, n_pcs=T, use_rep='X_pca')\n",
    "# Compute the Louvain clusters\n",
    "sc.tl.louvain(adata_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_label_1d_concat = np.concatenate((topic_label_1d, topic_label_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7954693479308023\n",
      "0.7954670520290507\n",
      "0.7954716496715548\n"
     ]
    }
   ],
   "source": [
    "nmi_pca_concat = normalized_mutual_info_score(topic_label_1d_concat, adata_concat.obs['louvain'])\n",
    "nmi_pca_concat_S = normalized_mutual_info_score(topic_label_1d, adata_concat.obs['louvain'][:N])\n",
    "nmi_pca_concat_U = normalized_mutual_info_score(topic_label_1d, adata_concat.obs['louvain'][N:])\n",
    "\n",
    "print(nmi_pca_concat)\n",
    "print(nmi_pca_concat_S)\n",
    "print(nmi_pca_concat_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.index.name = 'cell_id'\n",
    "adata.var.index.name = 'gene_id_spliced'\n",
    "adata.uns['sample_name'] = \"spliced\"\n",
    "\n",
    "adata_unspliced.obs.index.name = 'cell_id'\n",
    "adata_unspliced.var.index.name = 'gene_id_unspliced'\n",
    "adata_unspliced.uns['sample_name'] = \"unspliced\"\n",
    "\n",
    "liger_object = pyliger.create_liger([adata,adata_unspliced])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyliger.normalize(liger_object)\n",
    "pyliger.select_genes(liger_object)\n",
    "pyliger.scale_not_center(liger_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [10:24<00:00, 20.81s/it]\n"
     ]
    }
   ],
   "source": [
    "pyliger.optimize_ALS(liger_object, k = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyliger.quantile_norm(liger_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyliger.louvain_cluster(liger_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI_liger_S: 0.8283825783680144\n",
      "NMI_liger_U: 0.8045634616569967\n",
      "NMI_liger: 0.8009762287068639\n"
     ]
    }
   ],
   "source": [
    "W_spliced = liger_object.adata_list[0].obs['cluster']\n",
    "nmi_liger_S = normalized_mutual_info_score(topic_label_1d, W_spliced)\n",
    "W_unspliced = liger_object.adata_list[1].obs['cluster']\n",
    "nmi_liger_U = normalized_mutual_info_score(topic_label_1d, W_unspliced)\n",
    "nmi_liger = normalized_mutual_info_score(topic_label_1d_concat, np.concatenate((W_spliced, W_unspliced)))\n",
    "\n",
    "print(f\"NMI_liger_S: {nmi_liger_S}\")\n",
    "print(f\"NMI_liger_U: {nmi_liger_U}\")\n",
    "print(f\"NMI_liger: {nmi_liger}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 32000 × 8248\n",
       "    obs: 'topic_true', 'nUMI', 'nGene', 'dataset', 'cluster'\n",
       "    var: 'gene_sum', 'gene_sum_sq', 'nCell', 'norm_sum', 'norm_sum_sq', 'norm_mean', 'norm_var'\n",
       "    uns: 'deltaTopic', 'sample_name', 'var_gene_idx'\n",
       "    obsm: 'unspliced_expression', 'H', 'H_norm'\n",
       "    varm: 'W', 'V'\n",
       "    layers: 'counts', 'norm_data', 'scale_data'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liger_object.adata_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform NMF on spliced data\n",
    "from sklearn.decomposition import NMF\n",
    "model_NMF = NMF(n_components=T, init='random', random_state=0)\n",
    "W_nmf = model_NMF.fit_transform(adata.X)\n",
    "H_nmf = model_NMF.components_\n",
    "adata.obsm['X_nmf'] = W_nmf\n",
    "adata_NMF = adata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the PCA\n",
    "sc.tl.pca(adata_NMF.obsm['X_nmf'], svd_solver='arpack')\n",
    "# Compute the neighborhood graph\n",
    "sc.pp.neighbors(adata_NMF, n_pcs=T, use_rep='X_nmf')\n",
    "# Compute the Louvain clusters\n",
    "sc.tl.louvain(adata_NMF)\n",
    "nmi_nmf = normalized_mutual_info_score(topic_label_1d, adata_NMF.obs['louvain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized mutual information: 0.8378986635872715\n",
      "Normalized mutual information (NMF, spliced): 0.7948130306093455\n",
      "Normalized mutual information (PCA, concatenated): 0.7954693479308023\n",
      "Normalized mutual information (PCA, concat-spliced): 0.7954670520290507\n",
      "Normalized mutual information (PCA, concat-unspliced): 0.7954716496715548\n",
      "Normalized mutual information (PCA, spliced): 0.8048853714635366\n",
      "Normalized mutual information (LIGER, concatenated): 0.8009762287068639\n",
      "Normalized mutual information (LIGER, concat-spliced): 0.8283825783680144\n",
      "Normalized mutual information (LIGER, concat-unspliced): 0.8045634616569967\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalized mutual information:\", nmi)\n",
    "print(\"Normalized mutual information (NMF, spliced):\", nmi_nmf)\n",
    "print(\"Normalized mutual information (PCA, concatenated):\", nmi_pca_concat)\n",
    "print(\"Normalized mutual information (PCA, concat-spliced):\", nmi_pca_concat_S)\n",
    "print(\"Normalized mutual information (PCA, concat-unspliced):\", nmi_pca_concat_U)\n",
    "print(\"Normalized mutual information (PCA, spliced):\", nmi_pca)\n",
    "print(\"Normalized mutual information (LIGER, concatenated):\", nmi_liger)\n",
    "print(\"Normalized mutual information (LIGER, concat-spliced):\", nmi_liger_S)\n",
    "print(\"Normalized mutual information (LIGER, concat-unspliced):\", nmi_liger_U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_liger_object(liger_object, adata):\n",
    "    # Extract V_spliced and V_unspliced and create DataFrames\n",
    "    V_spliced = liger_object.adata_list[0].varm['V']\n",
    "    V_df_spliced = pd.DataFrame(V_spliced, index=liger_object.adata_list[0].var.index)\n",
    "\n",
    "    V_unspliced = liger_object.adata_list[1].varm['V']\n",
    "    V_df_unspliced = pd.DataFrame(V_unspliced, index=liger_object.adata_list[1].var.index)\n",
    "\n",
    "    V_W = liger_object.adata_list[0].varm['W']\n",
    "    V_df_W = pd.DataFrame(V_W, index=liger_object.adata_list[0].var.index)\n",
    "    \n",
    "    # Create full_df and join with V_df_spliced and V_df_unspliced\n",
    "    full_df = pd.DataFrame(index = adata.var.index)\n",
    "    full_df['gene_order'] = range(adata.var.index.shape[0])\n",
    "\n",
    "    df_spliced = full_df.join(V_df_spliced, how='outer')\n",
    "    df_spliced = df_spliced.fillna(0)\n",
    "    \n",
    "    df_unspliced = full_df.join(V_df_unspliced, how='outer')\n",
    "    df_unspliced = df_unspliced.fillna(0)\n",
    "\n",
    "    df_W = full_df.join(V_df_W, how='outer')\n",
    "    df_W = df_W.fillna(0)\n",
    "    # Sort by gene order\n",
    "    sorted_df_spliced = df_spliced.sort_values(by='gene_order')\n",
    "    sorted_df_unspliced = df_unspliced.sort_values(by='gene_order')\n",
    "    sorted_df_W = df_W.sort_values(by='gene_order')\n",
    "    return sorted_df_spliced, sorted_df_unspliced, sorted_df_W\n",
    "\n",
    "df_W_liger_spliced, df_W_liger_unspliced, sorted_df_W = process_liger_object(liger_object, adata)\n",
    "weight_liger_S = df_W_liger_spliced.iloc[:, 1:].T\n",
    "weight_liger_U = df_W_liger_unspliced.iloc[:, 1:].T\n",
    "weight_liger_W = sorted_df_W.iloc[:, 1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the rho and delta matrices\n",
    "rho = np.genfromtxt('data/rho_weight.csv', delimiter=',', skip_header=1)\n",
    "rho = rho[:,1:]\n",
    "delta = np.genfromtxt('data/delta_weight.csv', delimiter=',', skip_header=1)\n",
    "delta = delta[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    #\"rho\": weight_rho,\n",
    "    #\"delta\": weight_delta,\n",
    "    #\"pca_concat\": weight_pca_concat,\n",
    "    #\"pca_spliced\": weight_pca,\n",
    "    #\"liger_concat_S\": weight_liger_S,\n",
    "    #\"liger_concat_U\": weight_liger_U,\n",
    "    #\"nmf_spliced\":H_nmf,\n",
    "    \"liger_concat_W\": weight_liger_W,\n",
    "}\n",
    "betas = {\n",
    "    \"unspliced\": rho,\n",
    "    \"spliced\": delta,\n",
    "}\n",
    "df_out = pd.DataFrame()\n",
    "df_col_out = pd.DataFrame()\n",
    "\n",
    "for k in [10,20,30,40,50,100,300,500,1000,5000]:\n",
    "    \n",
    "    results = calculate_common_entries(weights, betas, k)\n",
    "\n",
    "    df, df_col = create_dataframe_from_results(results)\n",
    "    df[\"k\"] = k\n",
    "    df_col[\"k\"] = k\n",
    "    \n",
    "    df_out = pd.concat([df_out, df], ignore_index=True)\n",
    "    df_col_out = pd.concat([df_col_out, df_col], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "output_dir = os.path.join(\"models\", model_id, \"output\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "# Save the NMI values to a text file\n",
    "np.savetxt(os.path.join(output_dir, \"nmi_values_new.txt\"), [nmi, nmi_pca, nmi_pca_concat, nmi_pca_concat_S, nmi_pca_concat_U, nmi_liger, nmi_liger_S, nmi_liger_U, nmi_nmf])\n",
    "\n",
    "output_file = os.path.join(output_dir, \"common_rowmax_liger.csv\")\n",
    "df_out.to_csv(output_file, index=False)\n",
    "output_file = os.path.join(output_dir, \"common_colmax_liger.csv\")\n",
    "df_col_out.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
